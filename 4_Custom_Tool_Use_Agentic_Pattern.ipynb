{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Madhu-712/Agentic-Patterns-/blob/main/4_Custom_Tool_Use_Agentic_Pattern.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbWoGOis4KoG"
      },
      "source": [
        "# L4: Tools for a Customer Outreach Campaign\n",
        "\n",
        "In this lesson, you will learn more about Tools. You'll focus on three key elements of Tools:\n",
        "- Versatility\n",
        "- Fault Tolerance\n",
        "- Caching"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCr9u_byDx9G"
      },
      "source": [
        "The libraries are already installed in the classroom. If you're running this notebook on your own machine, you can install the following:\n",
        "```Python\n",
        "!pip install crewai==0.28.8 crewai_tools==0.1.6 langchain_community==0.0.29\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install crewai==0.28.8 crewai_tools==0.1.6 langchain_community==0.0.29"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jb8vU_M8deTE",
        "outputId": "1d95c13b-7890-4edc-f242-d85df5d87ce5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting crewai==0.28.8\n",
            "  Downloading crewai-0.28.8-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting crewai_tools==0.1.6\n",
            "  Downloading crewai_tools-0.1.6-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langchain_community==0.0.29\n",
            "  Downloading langchain_community-0.0.29-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting appdirs<2.0.0,>=1.4.4 (from crewai==0.28.8)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from crewai==0.28.8) (8.1.8)\n",
            "Collecting embedchain<0.2.0,>=0.1.98 (from crewai==0.28.8)\n",
            "  Downloading embedchain-0.1.126-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting instructor<0.6.0,>=0.5.2 (from crewai==0.28.8)\n",
            "  Downloading instructor-0.5.2-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting langchain<0.2.0,>=0.1.10 (from crewai==0.28.8)\n",
            "  Downloading langchain-0.1.20-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from crewai==0.28.8) (1.61.1)\n",
            "Collecting opentelemetry-api<2.0.0,>=1.22.0 (from crewai==0.28.8)\n",
            "  Downloading opentelemetry_api-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 (from crewai==0.28.8)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-sdk<2.0.0,>=1.22.0 (from crewai==0.28.8)\n",
            "  Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from crewai==0.28.8) (2.10.6)\n",
            "Collecting python-dotenv==1.0.0 (from crewai==0.28.8)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting regex<2024.0.0,>=2023.12.25 (from crewai==0.28.8)\n",
            "  Downloading regex-2023.12.25-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from crewai_tools==0.1.6) (4.13.3)\n",
            "Collecting chromadb<0.5.0,>=0.4.22 (from crewai_tools==0.1.6)\n",
            "  Downloading chromadb-0.4.24-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting lancedb<0.6.0,>=0.5.4 (from crewai_tools==0.1.6)\n",
            "  Downloading lancedb-0.5.7-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting pyright<2.0.0,>=1.1.350 (from crewai_tools==0.1.6)\n",
            "  Downloading pyright-1.1.393-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: pytest<9.0.0,>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from crewai_tools==0.1.6) (8.3.4)\n",
            "Collecting pytube<16.0.0,>=15.0.0 (from crewai_tools==0.1.6)\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from crewai_tools==0.1.6) (2.32.3)\n",
            "Collecting selenium<5.0.0,>=4.18.1 (from crewai_tools==0.1.6)\n",
            "  Downloading selenium-4.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community==0.0.29) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community==0.0.29) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community==0.0.29) (3.11.11)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community==0.0.29)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting langchain-core<0.2.0,>=0.1.33 (from langchain_community==0.0.29)\n",
            "  Downloading langchain_core-0.1.53-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.0 (from langchain_community==0.0.29)\n",
            "  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain_community==0.0.29) (1.26.4)\n",
            "Collecting tenacity<9.0.0,>=8.1.0 (from langchain_community==0.0.29)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (1.18.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->crewai_tools==0.1.6) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->crewai_tools==0.1.6) (4.12.2)\n",
            "Collecting build>=1.0.3 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting chroma-hnswlib==0.7.3 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading chroma_hnswlib-0.7.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading fastapi-0.115.8-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting posthog>=2.4.0 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading posthog-3.11.0-py2.py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting pulsar-client>=3.1.0 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading pulsar_client-3.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.51b0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.21.0)\n",
            "Collecting pypika>=0.48.9 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.70.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.15.1)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading kubernetes-32.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting mmh3>=4.0.1 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (3.10.15)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.0.29)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.0.29)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting alembic<2.0.0,>=1.13.1 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading alembic-1.14.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "INFO: pip is looking at multiple versions of embedchain to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting embedchain<0.2.0,>=0.1.98 (from crewai==0.28.8)\n",
            "  Downloading embedchain-0.1.125-py3-none-any.whl.metadata (9.3 kB)\n",
            "  Downloading embedchain-0.1.124-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting cohere<6.0,>=5.3 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading cohere-5.13.12-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.26.1 in /usr/local/lib/python3.11/dist-packages (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.79.0)\n",
            "Collecting gptcache<0.2.0,>=0.1.43 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading gptcache-0.1.44-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting embedchain<0.2.0,>=0.1.98 (from crewai==0.28.8)\n",
            "  Downloading embedchain-0.1.123-py3-none-any.whl.metadata (9.3 kB)\n",
            "  Downloading embedchain-0.1.122-py3-none-any.whl.metadata (9.3 kB)\n",
            "  Downloading embedchain-0.1.121-py3-none-any.whl.metadata (9.3 kB)\n",
            "  Downloading embedchain-0.1.120-py3-none-any.whl.metadata (9.3 kB)\n",
            "  Downloading embedchain-0.1.119-py3-none-any.whl.metadata (9.1 kB)\n",
            "INFO: pip is still looking at multiple versions of embedchain to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading embedchain-0.1.118-py3-none-any.whl.metadata (9.1 kB)\n",
            "  Downloading embedchain-0.1.117-py3-none-any.whl.metadata (9.1 kB)\n",
            "  Downloading embedchain-0.1.116-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting clarifai<11.0.0,>=10.0.1 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading clarifai-10.11.1-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting embedchain<0.2.0,>=0.1.98 (from crewai==0.28.8)\n",
            "  Downloading embedchain-0.1.115-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading embedchain-0.1.114-py3-none-any.whl.metadata (10 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading embedchain-0.1.113-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting langchain-cohere<0.2.0,>=0.1.4 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading langchain_cohere-0.1.9-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting langchain-openai<0.2.0,>=0.1.7 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading langchain_openai-0.1.25-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting pypdf<5.0.0,>=4.0.1 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting pysbd<0.4.0,>=0.3.4 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.7.0 in /usr/local/lib/python3.11/dist-packages (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (13.9.4)\n",
            "Collecting schema<0.8.0,>=0.7.5 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading schema-0.7.7-py2.py3-none-any.whl.metadata (34 kB)\n",
            "Collecting tiktoken<0.8.0,>=0.7.0 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "\u001b[33mWARNING: embedchain 0.1.126 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.126 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
            "\u001b[0mINFO: pip is looking at multiple versions of embedchain[github,youtube] to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[33mWARNING: embedchain 0.1.125 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.125 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.124 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.124 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.123 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.123 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.122 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.122 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.121 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.121 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.120 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.120 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.119 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.119 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
            "\u001b[0mINFO: pip is still looking at multiple versions of embedchain[github,youtube] to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[33mWARNING: embedchain 0.1.118 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.118 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.117 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.117 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting PyGithub<2.0.0,>=1.59.1 (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6)\n",
            "  Downloading PyGithub-1.59.1-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: gitpython<4.0.0,>=3.1.38 in /usr/local/lib/python3.11/dist-packages (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (3.1.44)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting youtube-transcript-api<0.7.0,>=0.6.1 (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6)\n",
            "  Downloading youtube_transcript_api-0.6.3-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting yt_dlp<2024.0.0,>=2023.11.14 (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6)\n",
            "  Downloading yt_dlp-2023.12.30-py2.py3-none-any.whl.metadata (160 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.7/160.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docstring-parser<0.16,>=0.15 (from instructor<0.6.0,>=0.5.2->crewai==0.28.8)\n",
            "  Downloading docstring_parser-0.15-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting typer>=0.9.0 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading typer-0.9.4-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting deprecation (from lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting pylance==0.9.18 (from lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6)\n",
            "  Downloading pylance-0.9.18-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
            "Collecting ratelimiter~=1.0 (from lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6)\n",
            "  Downloading ratelimiter-1.2.0.post0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting retry>=0.9.2 (from lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6)\n",
            "  Downloading retry-0.9.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting semver>=3.0 (from lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6)\n",
            "  Downloading semver-3.0.4-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6) (5.5.1)\n",
            "Requirement already satisfied: pyarrow>=12 in /usr/local/lib/python3.11/dist-packages (from pylance==0.9.18->lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6) (17.0.0)\n",
            "INFO: pip is looking at multiple versions of langchain to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain<0.2.0,>=0.1.10 (from crewai==0.28.8)\n",
            "  Downloading langchain-0.1.19-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading langchain-0.1.17-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain<0.2.0,>=0.1.10->crewai==0.28.8) (1.33)\n",
            "  Downloading langchain-0.1.16-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading langchain-0.1.15-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading langchain-0.1.14-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading langchain-0.1.13-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain<0.2.0,>=0.1.10->crewai==0.28.8)\n",
            "  Downloading langchain_text_splitters-0.0.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.33->langchain_community==0.0.29)\n",
            "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community==0.0.29) (0.28.1)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community==0.0.29) (1.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.13.3->crewai==0.28.8) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.13.3->crewai==0.28.8) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.13.3->crewai==0.28.8) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.13.3->crewai==0.28.8) (1.3.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<2.0.0,>=1.22.0->crewai==0.28.8) (1.2.18)\n",
            "Collecting importlib-metadata<=8.5.0,>=6.0 (from opentelemetry-api<2.0.0,>=1.22.0->crewai==0.28.8)\n",
            "  Downloading importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai==0.28.8) (1.66.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.30.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai==0.28.8)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.30.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.30.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai==0.28.8)\n",
            "  Downloading opentelemetry_proto-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting protobuf<6.0,>=5.0 (from opentelemetry-proto==1.30.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai==0.28.8)\n",
            "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting opentelemetry-semantic-conventions==0.51b0 (from opentelemetry-sdk<2.0.0,>=1.22.0->crewai==0.28.8)\n",
            "  Downloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.4.2->crewai==0.28.8) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.4.2->crewai==0.28.8) (2.27.2)\n",
            "Collecting nodeenv>=1.6.0 (from pyright<2.0.0,>=1.1.350->crewai_tools==0.1.6)\n",
            "  Downloading nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest<9.0.0,>=8.0.0->crewai_tools==0.1.6) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest<9.0.0,>=8.0.0->crewai_tools==0.1.6) (1.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->crewai_tools==0.1.6) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->crewai_tools==0.1.6) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->crewai_tools==0.1.6) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->crewai_tools==0.1.6) (2025.1.31)\n",
            "Collecting trio~=0.17 (from selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6)\n",
            "  Downloading trio-0.28.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting trio-websocket~=0.9 (from selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.11/dist-packages (from selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6) (1.8.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community==0.0.29) (3.1.1)\n",
            "Collecting Mako (from alembic<2.0.0,>=1.13.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting clarifai-grpc>=10.11.2 (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading clarifai_grpc-11.1.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting clarifai-protocol>=0.0.14 (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading clarifai_protocol-0.0.18-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting tritonclient>=2.34.0 (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading tritonclient-2.54.0-py3-none-manylinux1_x86_64.whl.metadata (2.8 kB)\n",
            "Collecting schema<0.8.0,>=0.7.5 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading schema-0.7.5-py2.py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: Pillow>=9.5.0 in /usr/local/lib/python3.11/dist-packages (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (11.1.0)\n",
            "Collecting inquirerpy==0.3.4 (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading InquirerPy-0.3.4-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: tabulate>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.9.0)\n",
            "Collecting fsspec==2024.6.1 (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting click<9.0.0,>=8.1.7 (from crewai==0.28.8)\n",
            "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting contextlib2>=0.5.5 (from schema<0.8.0,>=0.7.5->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting pfzy<0.4.0,>=0.3.1 (from inquirerpy==0.3.4->clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading pfzy-0.3.4-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from inquirerpy==0.3.4->clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (3.0.50)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api<2.0.0,>=1.22.0->crewai==0.28.8) (1.17.2)\n",
            "Collecting starlette<0.46.0,>=0.40.0 (from fastapi>=0.95.2->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4.0.0,>=3.1.38->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (4.0.12)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.19.2)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.26.0)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.19.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (3.25.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.14.0)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.0.7)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community==0.0.29) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community==0.0.29) (0.14.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api<2.0.0,>=1.22.0->crewai==0.28.8) (3.21.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain<0.2.0,>=0.1.10->crewai==0.28.8) (3.0.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (2.8.2)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (3.2.2)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "INFO: pip is looking at multiple versions of langchain-cohere to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-cohere<0.2.0,>=0.1.4 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading langchain_cohere-0.1.8-py3-none-any.whl.metadata (6.4 kB)\n",
            "  Downloading langchain_cohere-0.1.7-py3-none-any.whl.metadata (6.4 kB)\n",
            "  Downloading langchain_cohere-0.1.5-py3-none-any.whl.metadata (6.4 kB)\n",
            "INFO: pip is looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-openai<0.2.0,>=0.1.7 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading langchain_openai-0.1.24-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading langchain_openai-0.1.23-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading langchain_openai-0.1.22-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading langchain_openai-0.1.20-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading langchain_openai-0.1.19-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading langchain_openai-0.1.17-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.1.16-py3-none-any.whl.metadata (2.5 kB)\n",
            "INFO: pip is still looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading langchain_openai-0.1.15-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.1.14-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.1.13-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.1.12-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.1.11-py3-none-any.whl.metadata (2.5 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading langchain_openai-0.1.10-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.1.9-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.1.7-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (25.1.24)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.13.1)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.51b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-instrumentation==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading opentelemetry_instrumentation-0.51b0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting opentelemetry-util-http==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading opentelemetry_util_http-0.51b0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: pyjwt>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from pyjwt[crypto]>=2.4.0->PyGithub<2.0.0,>=1.59.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (2.10.1)\n",
            "Collecting pynacl>=1.4.0 (from PyGithub<2.0.0,>=1.59.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6)\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: decorator>=3.4.2 in /usr/local/lib/python3.11/dist-packages (from retry>=0.9.2->lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6) (4.4.2)\n",
            "Collecting py<2.0.0,>=1.4.26 (from retry>=0.9.2->lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6)\n",
            "  Downloading py-1.11.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.7.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.7.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.28.1)\n",
            "Collecting sortedcontainers (from trio~=0.17->selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting outcome (from trio~=0.17->selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community==0.0.29)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6) (1.7.1)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (14.2)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from youtube-transcript-api<0.7.0,>=0.6.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (0.7.1)\n",
            "Collecting mutagen (from yt_dlp<2024.0.0,>=2023.11.14->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6)\n",
            "  Downloading mutagen-1.47.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting pycryptodomex (from yt_dlp<2024.0.0,>=2023.11.14->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6)\n",
            "  Downloading pycryptodomex-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting brotli (from yt_dlp<2024.0.0,>=2023.11.14->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6)\n",
            "  Downloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "INFO: pip is looking at multiple versions of clarifai-protocol to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting clarifai-protocol>=0.0.14 (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading clarifai_protocol-0.0.16-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "  Downloading clarifai_protocol-0.0.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting fastavro<2.0.0,>=1.9.4 (from cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading fastavro-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting httpx-sse==0.4.0 (from cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading types_requests-2.32.0.20241016-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4.0.0,>=3.1.38->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (5.0.2)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.62.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (4.9)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.7.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.14.0)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (3.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.1.2)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.11/dist-packages (from pyjwt[crypto]>=2.4.0->PyGithub<2.0.0,>=1.59.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from pynacl>=1.4.0->PyGithub<2.0.0,>=1.59.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (1.17.1)\n",
            "Collecting python-rapidjson>=0.9.1 (from tritonclient>=2.34.0->clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading python_rapidjson-1.20-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic<2.0.0,>=1.13.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.4.1->pynacl>=1.4.0->PyGithub<2.0.0,>=1.59.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (2.22)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit<4.0.0,>=3.0.1->inquirerpy==0.3.4->clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.2.13)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.6.1)\n",
            "Downloading crewai-0.28.8-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading crewai_tools-0.1.6-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.0.29-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading chromadb-0.4.24-py3-none-any.whl (525 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading embedchain-0.1.113-py3-none-any.whl (202 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.6/202.6 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading instructor-0.5.2-py3-none-any.whl (33 kB)\n",
            "Downloading lancedb-0.5.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.1/115.1 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pylance-0.9.18-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.6/21.6 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.1.13-py3-none-any.whl (810 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.5/810.5 kB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.1.53-py3-none-any.whl (303 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.1/303.1 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.30.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_http-1.30.0-py3-none-any.whl (17 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.30.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.30.0-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.30.0-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl (177 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyright-1.1.393-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m90.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading regex-2023.12.25-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (785 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m785.1/785.1 kB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading selenium-4.28.1-py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading alembic-1.14.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading clarifai-10.11.1-py3-none-any.whl (167 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.3/167.3 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading schema-0.7.5-py2.py3-none-any.whl (17 kB)\n",
            "Downloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading InquirerPy-0.3.4-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docstring_parser-0.15-py3-none-any.whl (36 kB)\n",
            "Downloading fastapi-0.115.8-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gptcache-0.1.44-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
            "Downloading kubernetes-32.0.0-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_cohere-0.1.5-py3-none-any.whl (30 kB)\n",
            "Downloading langchain_openai-0.1.7-py3-none-any.whl (34 kB)\n",
            "Downloading langchain_text_splitters-0.0.2-py3-none-any.whl (23 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
            "Downloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.30.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_instrumentation_fastapi-0.51b0-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.51b0-py3-none-any.whl (30 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.51b0-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_util_http-0.51b0-py3-none-any.whl (7.3 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading posthog-3.11.0-py2.py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pulsar_client-3.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyGithub-1.59.1-py3-none-any.whl (342 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m342.2/342.2 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ratelimiter-1.2.0.post0-py3-none-any.whl (6.6 kB)\n",
            "Downloading retry-0.9.2-py2.py3-none-any.whl (8.0 kB)\n",
            "Downloading semver-3.0.4-py3-none-any.whl (17 kB)\n",
            "Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio-0.28.0-py3-none-any.whl (486 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.3/486.3 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Downloading typer-0.9.4-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading youtube_transcript_api-0.6.3-py3-none-any.whl (622 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m622.3/622.3 kB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yt_dlp-2023.12.30-py2.py3-none-any.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading clarifai_grpc-11.1.0-py3-none-any.whl (262 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.1/262.1 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading clarifai_protocol-0.0.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (370 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m370.9/370.9 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cohere-5.13.12-py3-none-any.whl (252 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.9/252.9 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tritonclient-2.54.0-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m96.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Downloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading pycryptodomex-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading fastavro-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pfzy-0.3.4-py3-none-any.whl (8.5 kB)\n",
            "Downloading python_rapidjson-1.20-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.0.20241016-py3-none-any.whl (15 kB)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53771 sha256=fb8a29ac43cbc5c5cd690c47e2c4160f215a87ac3aef6bd17df65c6a96731e78\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pypika\n",
            "Installing collected packages: sortedcontainers, ratelimiter, pypika, monotonic, durationpy, brotli, appdirs, wsproto, uvloop, types-requests, tenacity, semver, regex, pytube, python-rapidjson, python-dotenv, pysbd, pyproject_hooks, pypdf, pycryptodomex, py, pulsar-client, protobuf, pfzy, packaging, overrides, outcome, opentelemetry-util-http, nodeenv, mypy-extensions, mutagen, mmh3, Mako, importlib-metadata, humanfriendly, httpx-sse, httptools, fsspec, fastavro, docstring-parser, contextlib2, click, chroma-hnswlib, bcrypt, backoff, asgiref, yt_dlp, youtube-transcript-api, watchfiles, uvicorn, typing-inspect, typer, tritonclient, trio, tiktoken, starlette, schema, retry, pyright, pynacl, pylance, posthog, opentelemetry-proto, opentelemetry-api, marshmallow, inquirerpy, gptcache, deprecation, coloredlogs, build, alembic, trio-websocket, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, onnxruntime, langsmith, lancedb, kubernetes, fastapi, dataclasses-json, clarifai-grpc, selenium, PyGithub, opentelemetry-sdk, opentelemetry-instrumentation, langchain-core, instructor, cohere, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, langchain-text-splitters, langchain-openai, langchain_community, langchain-cohere, opentelemetry-instrumentation-fastapi, langchain, chromadb, clarifai-protocol, clarifai, embedchain, crewai_tools, crewai\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2024.11.6\n",
            "    Uninstalling regex-2024.11.6:\n",
            "      Successfully uninstalled regex-2024.11.6\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.6\n",
            "    Uninstalling protobuf-4.25.6:\n",
            "      Successfully uninstalled protobuf-4.25.6\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.2\n",
            "    Uninstalling packaging-24.2:\n",
            "      Successfully uninstalled packaging-24.2\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.6.1\n",
            "    Uninstalling importlib_metadata-8.6.1:\n",
            "      Successfully uninstalled importlib_metadata-8.6.1\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "  Attempting uninstall: docstring-parser\n",
            "    Found existing installation: docstring_parser 0.16\n",
            "    Uninstalling docstring_parser-0.16:\n",
            "      Successfully uninstalled docstring_parser-0.16\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.1.8\n",
            "    Uninstalling click-8.1.8:\n",
            "      Successfully uninstalled click-8.1.8\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.15.1\n",
            "    Uninstalling typer-0.15.1:\n",
            "      Successfully uninstalled typer-0.15.1\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.16.0\n",
            "    Uninstalling opentelemetry-api-1.16.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.16.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.37b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.37b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.37b0\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.3.5\n",
            "    Uninstalling langsmith-0.3.5:\n",
            "      Successfully uninstalled langsmith-0.3.5\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.16.0\n",
            "    Uninstalling opentelemetry-sdk-1.16.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.16.0\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.33\n",
            "    Uninstalling langchain-core-0.3.33:\n",
            "      Successfully uninstalled langchain-core-0.3.33\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.5\n",
            "    Uninstalling langchain-text-splitters-0.3.5:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.5\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.17\n",
            "    Uninstalling langchain-0.3.17:\n",
            "      Successfully uninstalled langchain-0.3.17\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.6.1 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Mako-1.3.9 PyGithub-1.59.1 alembic-1.14.1 appdirs-1.4.4 asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.1 brotli-1.1.0 build-1.2.2.post1 chroma-hnswlib-0.7.3 chromadb-0.4.24 clarifai-10.11.1 clarifai-grpc-11.1.0 clarifai-protocol-0.0.14 click-8.1.7 cohere-5.13.12 coloredlogs-15.0.1 contextlib2-21.6.0 crewai-0.28.8 crewai_tools-0.1.6 dataclasses-json-0.6.7 deprecation-2.1.0 docstring-parser-0.15 durationpy-0.9 embedchain-0.1.113 fastapi-0.115.8 fastavro-1.10.0 fsspec-2024.6.1 gptcache-0.1.44 httptools-0.6.4 httpx-sse-0.4.0 humanfriendly-10.0 importlib-metadata-8.5.0 inquirerpy-0.3.4 instructor-0.5.2 kubernetes-32.0.0 lancedb-0.5.7 langchain-0.1.13 langchain-cohere-0.1.5 langchain-core-0.1.53 langchain-openai-0.1.7 langchain-text-splitters-0.0.2 langchain_community-0.0.29 langsmith-0.1.147 marshmallow-3.26.1 mmh3-5.1.0 monotonic-1.6 mutagen-1.47.0 mypy-extensions-1.0.0 nodeenv-1.9.1 onnxruntime-1.20.1 opentelemetry-api-1.30.0 opentelemetry-exporter-otlp-proto-common-1.30.0 opentelemetry-exporter-otlp-proto-grpc-1.30.0 opentelemetry-exporter-otlp-proto-http-1.30.0 opentelemetry-instrumentation-0.51b0 opentelemetry-instrumentation-asgi-0.51b0 opentelemetry-instrumentation-fastapi-0.51b0 opentelemetry-proto-1.30.0 opentelemetry-sdk-1.30.0 opentelemetry-semantic-conventions-0.51b0 opentelemetry-util-http-0.51b0 outcome-1.3.0.post0 overrides-7.7.0 packaging-23.2 pfzy-0.3.4 posthog-3.11.0 protobuf-5.29.3 pulsar-client-3.6.0 py-1.11.0 pycryptodomex-3.21.0 pylance-0.9.18 pynacl-1.5.0 pypdf-4.3.1 pypika-0.48.9 pyproject_hooks-1.2.0 pyright-1.1.393 pysbd-0.3.4 python-dotenv-1.0.0 python-rapidjson-1.20 pytube-15.0.0 ratelimiter-1.2.0.post0 regex-2023.12.25 retry-0.9.2 schema-0.7.5 selenium-4.28.1 semver-3.0.4 sortedcontainers-2.4.0 starlette-0.45.3 tenacity-8.5.0 tiktoken-0.7.0 trio-0.28.0 trio-websocket-0.11.1 tritonclient-2.54.0 typer-0.9.4 types-requests-2.32.0.20241016 typing-inspect-0.9.0 uvicorn-0.34.0 uvloop-0.21.0 watchfiles-1.0.4 wsproto-1.2.0 youtube-transcript-api-0.6.3 yt_dlp-2023.12.30\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "importlib_metadata"
                ]
              },
              "id": "0bdd4aec2234426899f1631ced195abd"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 63,
        "id": "_LQ5_lop4KJq"
      },
      "outputs": [],
      "source": [
        "# Warning control\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHmuFTM3Dx9I"
      },
      "source": [
        "- Import libraries, APIs and LLM\n",
        "- [Serper](https://serper.dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 29,
        "id": "FKJ4s0KnDx9I"
      },
      "outputs": [],
      "source": [
        "from crewai import Agent, Task, Crew"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_0djQ3wDx9J"
      },
      "source": [
        "**Note**:\n",
        "- The video uses `gpt-4-turbo`, but due to certain constraints, and in order to offer this course for free to everyone, the code you'll run here will use `gpt-3.5-turbo`.\n",
        "- You can use `gpt-4-turbo` when you run the notebook _locally_ (using `gpt-4-turbo` will not work on the platform)\n",
        "- Thank you for your understanding!"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QMIwoQXzdy1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 131,
        "id": "0Xa2q2OFDx9K"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# from utils import get_openai_api_key, pretty_print_result\n",
        "# from utils import get_serper_api_key\n",
        "\n",
        "# openai_api_key = get_openai_api_key()\n",
        "os.environ[\"OPENAI_MODEL_NAME\"] = 'gpt-4o'\n",
        "# os.environ[\"SERPER_API_KEY\"] = get_serper_api_key()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzGZM80bDx9L"
      },
      "source": [
        "## Creating Agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 333,
        "id": "FCt4kKLQDx9L"
      },
      "outputs": [],
      "source": [
        "sales_rep_agent = Agent(\n",
        "    role=\"Sales Representative\",\n",
        "    goal=\"Identify high-value leads that match \"\n",
        "         \"our ideal customer profile\",\n",
        "    backstory=(\n",
        "        \"As a part of the dynamic sales team at CrewAI, \"\n",
        "        \"your mission is to scour \"\n",
        "        \"the digital landscape for potential leads. \"\n",
        "        \"Armed with cutting-edge tools \"\n",
        "        \"and a strategic mindset, you analyze data, \"\n",
        "        \"trends, and interactions to \"\n",
        "        \"unearth opportunities that others might overlook. \"\n",
        "        \"Your work is crucial in paving the way \"\n",
        "        \"for meaningful engagements and driving the company's growth.\"\n",
        "    ),\n",
        "    allow_delegation=False,\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 316,
        "id": "nsi8ztBtDx9M"
      },
      "outputs": [],
      "source": [
        "lead_sales_rep_agent = Agent(\n",
        "    role=\"Lead Sales Representative\",\n",
        "    goal=\"Nurture leads with personalized, compelling communications\",\n",
        "    backstory=(\n",
        "        \"Within the vibrant ecosystem of CrewAI's sales department, \"\n",
        "        \"you stand out as the bridge between potential clients \"\n",
        "        \"and the solutions they need.\"\n",
        "        \"By creating engaging, personalized messages, \"\n",
        "        \"you not only inform leads about our offerings \"\n",
        "        \"but also make them feel seen and heard.\"\n",
        "        \"Your role is pivotal in converting interest \"\n",
        "        \"into action, guiding leads through the journey \"\n",
        "        \"from curiosity to commitment.\"\n",
        "    ),\n",
        "    allow_delegation=False,\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpnLVGNrDx9M"
      },
      "source": [
        "## Creating Tools\n",
        "\n",
        "### crewAI Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 63,
        "id": "-AHuYPxVDx9M"
      },
      "outputs": [],
      "source": [
        "from crewai_tools import DirectoryReadTool, \\\n",
        "                         FileReadTool, \\\n",
        "                         SerperDevTool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 78,
        "id": "LfMUSRp9Dx9M"
      },
      "outputs": [],
      "source": [
        "directory_read_tool = DirectoryReadTool(directory='/home/badrinarayan/Downloads/instructions')\n",
        "file_read_tool = FileReadTool()\n",
        "search_tool = SerperDevTool()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUuNcLUzDx9N"
      },
      "source": [
        "### Custom Tool\n",
        "- Create a custom tool using crewAi's [BaseTool](https://docs.crewai.com/core-concepts/Tools/#subclassing-basetool) class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 29,
        "id": "LEZinekeDx9N"
      },
      "outputs": [],
      "source": [
        "from crewai_tools import BaseTool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6waOtL1Dx9N"
      },
      "source": [
        "- Every Tool needs to have a `name` and a `description`.\n",
        "- For simplicity and classroom purposes, `SentimentAnalysisTool` will return `positive` for every text.\n",
        "- When running locally, you can customize the code with your logic in the `_run` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 335,
        "id": "GW3InCuWDx9N"
      },
      "outputs": [],
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "class SentimentAnalysisTool(BaseTool):\n",
        "    name: str =\"Sentiment Analysis Tool\"\n",
        "    description: str = (\"Analyzes the sentiment of text \"\n",
        "         \"to ensure positive and engaging communication.\")\n",
        "\n",
        "    def _run(self, text: str) -> str:\n",
        "        # Perform sentiment analysis using TextBlob\n",
        "        analysis = TextBlob(text)\n",
        "        polarity = analysis.sentiment.polarity\n",
        "\n",
        "        # Determine sentiment based on polarity\n",
        "        if polarity > 0:\n",
        "            return \"positive\"\n",
        "        elif polarity < 0:\n",
        "            return \"negative\"\n",
        "        else:\n",
        "            return \"neutral\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 29,
        "id": "xbh5abY1Dx9N"
      },
      "outputs": [],
      "source": [
        "sentiment_analysis_tool = SentimentAnalysisTool()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqJ2e01UDx9O"
      },
      "source": [
        "## Creating Tasks\n",
        "\n",
        "- The Lead Profiling Task is using crewAI Tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 454,
        "id": "P74nCsXeDx9O"
      },
      "outputs": [],
      "source": [
        "lead_profiling_task = Task(\n",
        "    description=(\n",
        "        \"Conduct an in-depth analysis of {lead_name}, \"\n",
        "        \"a company in the {industry} sector \"\n",
        "        \"that recently showed interest in our solutions. \"\n",
        "        \"Utilize all available data sources \"\n",
        "        \"to compile a detailed profile, \"\n",
        "        \"focusing on key decision-makers, recent business \"\n",
        "        \"developments, and potential needs \"\n",
        "        \"that align with our offerings. \"\n",
        "        \"This task is crucial for tailoring \"\n",
        "        \"our engagement strategy effectively.\\n\"\n",
        "        \"Don't make assumptions and \"\n",
        "        \"only use information you absolutely sure about.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A comprehensive report on {lead_name}, \"\n",
        "        \"including company background, \"\n",
        "        \"key personnel, recent milestones, and identified needs. \"\n",
        "        \"Highlight potential areas where \"\n",
        "        \"our solutions can provide value, \"\n",
        "        \"and suggest personalized engagement strategies.\"\n",
        "    ),\n",
        "    tools=[directory_read_tool, file_read_tool, search_tool],\n",
        "    agent=sales_rep_agent,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjd5eYftDx9O"
      },
      "source": [
        "- The Personalized Outreach Task is using your custom Tool `SentimentAnalysisTool`, as well as crewAI's `SerperDevTool` (search_tool)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 505,
        "id": "URz0sEm7Dx9O"
      },
      "outputs": [],
      "source": [
        "personalized_outreach_task = Task(\n",
        "    description=(\n",
        "        \"Using the insights gathered from \"\n",
        "        \"the lead profiling report on {lead_name}, \"\n",
        "        \"craft a personalized outreach campaign \"\n",
        "        \"aimed at {key_decision_maker}, \"\n",
        "        \"the {position} of {lead_name}. \"\n",
        "        \"The campaign should address their recent {milestone} \"\n",
        "        \"and how our solutions can support their goals. \"\n",
        "        \"Your communication must resonate \"\n",
        "        \"with {lead_name}'s company culture and values, \"\n",
        "        \"demonstrating a deep understanding of \"\n",
        "        \"their business and needs.\\n\"\n",
        "        \"Don't make assumptions and only \"\n",
        "        \"use information you absolutely sure about.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A series of personalized email drafts \"\n",
        "        \"tailored to {lead_name}, \"\n",
        "        \"specifically targeting {key_decision_maker}.\"\n",
        "        \"Each draft should include \"\n",
        "        \"a compelling narrative that connects our solutions \"\n",
        "        \"with their recent achievements and future goals. \"\n",
        "        \"Ensure the tone is engaging, professional, \"\n",
        "        \"and aligned with {lead_name}'s corporate identity.\"\n",
        "        \"Use sentiment analysis tool to get the tone, if positive go ahead.\"\n",
        "    ),\n",
        "    tools=[sentiment_analysis_tool, search_tool],\n",
        "    agent=lead_sales_rep_agent,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QppRag5NDx9O"
      },
      "source": [
        "## Creating the Crew"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 182,
        "id": "DAR2WV0zDx9P"
      },
      "outputs": [],
      "source": [
        "crew = Crew(\n",
        "    agents=[sales_rep_agent,\n",
        "            lead_sales_rep_agent],\n",
        "\n",
        "    tasks=[lead_profiling_task,\n",
        "           personalized_outreach_task],\n",
        "\n",
        "    verbose=2,\n",
        "\tmemory=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wl-v75VDx9P"
      },
      "source": [
        "## Running the Crew\n",
        "\n",
        "**Note**: LLMs can provide different outputs for they same input, so what you get might be different than what you see in the video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 165,
        "id": "rSxpvN_wDx9R",
        "outputId": "171d21c0-91ab-4e0d-b5d9-4c49773b104b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Sales Representative\u001b[00m\n",
            "\u001b[1m\u001b[95m [INFO]: == Starting Task: Conduct an in-depth analysis of DeepLearningAI, a company in the Online Learning Platform sector that recently showed interest in our solutions. Utilize all available data sources to compile a detailed profile, focusing on key decision-makers, recent business developments, and potential needs that align with our offerings. This task is crucial for tailoring our engagement strategy effectively.\n",
            "Don't make assumptions and only use information you absolutely sure about.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mTo conduct an in-depth analysis of DeepLearningAI, I need to gather information about the company, focusing on key personnel, recent milestones, and potential needs. I'll start by searching the internet for relevant information about DeepLearningAI.\n",
            "\n",
            "Action: Search the internet\n",
            "Action Input: {\"search_query\": \"DeepLearningAI company profile\"}\u001b[0m\u001b[95m \n",
            "\n",
            "\n",
            "Search results: Title: Deeplearning.ai - Crunchbase Company Profile & Funding\n",
            "Link: https://www.crunchbase.com/organization/deeplearning-ai\n",
            "Snippet: Deeplearning.ai is company that explores the frontier of AI. The company is founded by Andrew Ng, the former Chief Scientist of Baidu and the current ...\n",
            "---\n",
            "Title: DeepLearning.AI - LinkedIn\n",
            "Link: https://www.linkedin.com/company/deeplearningai\n",
            "Snippet: DeepLearning.AI is making a world-class AI education accessible to people around the globe. DeepLearning.AI was founded by Andrew Ng, a global leader in AI.\n",
            "---\n",
            "Title: DEEPLEARNING.AI LLC Company Profile | Palo Alto, CA\n",
            "Link: https://www.dnb.com/business-directory/company-profiles.deeplearningai_llc.7cb525da4ad45b067062d87d5fbcad0b.html\n",
            "Snippet: Find company research, competitor information, contact details & financial data for DEEPLEARNING.AI LLC of Palo Alto, CA. Get the latest business insights ...\n",
            "---\n",
            "Title: DeepLearning.AI: Start or Advance Your Career in AI\n",
            "Link: https://www.deeplearning.ai/\n",
            "Snippet: Join over 7 million people learning how to use and build AI. AI Courses and Specializations. Build a foundation of machine learning and AI skills.\n",
            "---\n",
            "Title: Deeplearning - Company Profile - Tracxn\n",
            "Link: https://tracxn.com/d/companies/deeplearning/__SekrcD6K_o4Cvm4SgstSYBIp1zHk-3FzPsR3SkeAgnE\n",
            "Snippet: Deeplearning - Online platform providing multi-disciplinary learning courses. Raised funding from 1 investor. Founded by Andrew Ng in the year 2017.\n",
            "---\n",
            "Title: DeepLearning.AI Company Overview, Contact Details & Competitors\n",
            "Link: https://leadiq.com/c/deeplearningai/5aadd7b7550000d200cae52d\n",
            "Snippet: DeepLearning.AI is making a world-class AI education accessible to people around the globe. DeepLearning.AI was founded by Andrew Ng, a global leader in AI.\n",
            "---\n",
            "Title: deeplearning.ai Information - RocketReach\n",
            "Link: https://rocketreach.co/deeplearningai-profile_b4556bbefc954d11\n",
            "Snippet: deeplearning.ai is an Artificial Intelligence, Data and Analytics, and Deep Learning company located in Palo Alto, California with 241 employees.\n",
            "---\n",
            "Title: Deep Learning Analytics Company Profile 2024 - PitchBook\n",
            "Link: https://pitchbook.com/profiles/company/266531-05\n",
            "Snippet: Information on acquisition, funding, investors, and executives for Deep Learning Analytics. Use the PitchBook Platform to explore the full profile.\n",
            "---\n",
            "Title: DeepLearning.AI - LinkedIn\n",
            "Link: https://in.linkedin.com/company/deeplearningai\n",
            "Snippet: DeepLearning.AI is making a world-class AI education accessible to people around the globe. DeepLearning.AI was founded by Andrew Ng, a global leader in AI.\n",
            "---\n",
            "\n",
            "\u001b[00m\n",
            "\u001b[32;1m\u001b[1;3mThought: I have found several sources that provide information about DeepLearningAI. I will start by exploring the Crunchbase profile to gather detailed company information, then proceed to other sources if necessary.\n",
            "\n",
            "Action: Search the internet\n",
            "Action Input: {\"search_query\": \"DeepLearningAI Crunchbase profile\"}\u001b[0m\u001b[95m \n",
            "\n",
            "\n",
            "Search results: Title: Deeplearning.ai - Contacts, Employees, Board Members, Advisors ...\n",
            "Link: https://www.crunchbase.com/organization/deeplearning-ai/people\n",
            "Snippet: Deeplearning.ai has 4 current employee profiles, including Chief Operating Officer Jonathan Heyne . Deeplearning.ai has 1 board member or advisor, ...\n",
            "---\n",
            "Title: Deeplearning.ai - Crunchbase\n",
            "Link: https://www.crunchbase.com/organization/deeplearning-ai/org_similarity_overview\n",
            "Snippet: Deeplearning.ai is company that explores the frontier of AI ... Profile · Featured Lists and Searches · The Crunchbase Difference · Knowledge ...\n",
            "---\n",
            "Title: DeepLearning.net - Crunchbase Company Profile & Funding\n",
            "Link: https://www.crunchbase.com/organization/deep-learning\n",
            "Snippet: Deep Learning is a website that publishes information on deep learning, a new area of machine learning research.\n",
            "---\n",
            "Title: DeepLearning.AI - LinkedIn\n",
            "Link: https://www.linkedin.com/company/deeplearningai\n",
            "Snippet: DeepLearning.AI is making a world-class AI education accessible to people around the globe. DeepLearning.AI was founded by Andrew Ng, a global leader in AI.\n",
            "---\n",
            "Title: Deeplearning.ai - Updates, News, Events, Signals & Triggers\n",
            "Link: https://www.crunchbase.com/organization/deeplearning-ai/signals_and_news\n",
            "Snippet: Deeplearning.ai has been active in educational initiatives, including a free short course on automating LLM evaluations in collaboration with CircleCI, and a ...\n",
            "---\n",
            "Title: Andrew Ng - Executive Chairman and Founder @ LandingAI\n",
            "Link: https://www.crunchbase.com/person/andrew-ng\n",
            "Snippet: Andrew Ng has 7 current jobs including Managing General Partner at AI Fund , Executive Chairman and Founder at LandingAI , and Founder and CEO at Deeplearning.\n",
            "---\n",
            "Title: About - DeepLearning.AI\n",
            "Link: https://www.deeplearning.ai/about/\n",
            "Snippet: DeepLearning.AI is an education technology company that is empowering the global workforce to build an AI-powered future through world-class education.\n",
            "---\n",
            "Title: Andrew Ng - Founder and CEO @ Deeplearning.ai - Crunchbase\n",
            "Link: https://www.crunchbase.com/person/andrew-ng/person_overview_investor/timeline\n",
            "Snippet: Andrew Ng is the Founder of DeepLearning.AI. He previously worked at drive.ai as a Member of Board Of Directors. Andrew Ng attended the Univ...\n",
            "---\n",
            "Title: Deeplearning.ai - Tech Stack, Apps, Patents & Trademarks\n",
            "Link: https://www.crunchbase.com/organization/deeplearning-ai/technology\n",
            "Snippet: Deeplearning.ai uses 11 technology products and services including HTML5 , jQuery , and Google Analytics , according to G2 Stack.\n",
            "---\n",
            "\n",
            "\u001b[00m\n",
            "\u001b[32;1m\u001b[1;3mThought: I have found more detailed information about DeepLearningAI on Crunchbase, including employee profiles and recent initiatives. I'll read the Crunchbase profile to get comprehensive information about the company.\n",
            "\n",
            "Action: Search the internet\n",
            "Action Input: {\"search_query\": \"DeepLearningAI Crunchbase profile\"}\u001b[0m\u001b[95m \n",
            "\n",
            "I tried reusing the same input, I must stop using this action input. I'll try something else instead.\n",
            "\n",
            "\n",
            "\u001b[00m\n",
            "\u001b[32;1m\u001b[1;3mTo gather more information on DeepLearningAI, I should explore other sources that I came across during the initial search. I'll start by checking the LinkedIn profile of DeepLearningAI for more insights into their team and recent activities.\n",
            "\n",
            "Action: Search the internet\n",
            "Action Input: {\"search_query\": \"DeepLearningAI LinkedIn profile\"}\u001b[0m\u001b[95m \n",
            "\n",
            "\n",
            "Search results: Title: DeepLearning.AI - LinkedIn\n",
            "Link: https://www.linkedin.com/company/deeplearningai\n",
            "Snippet: Learn the skills to start or advance your AI career. World-class education. Hands-on training. Collaborative community of peers and mentors.\n",
            "---\n",
            "Title: DeepLearning.AI | LinkedIn\n",
            "Link: https://www.linkedin.com/company/deeplearningai/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--VtwIvHfKivYlfyAZ360KRq5RUIll9pEUvvRY7EgVGHSm3X-0-Fd1MShss5sfYFz2pRbnE\n",
            "Snippet: Learn the skills to start or advance your AI career | World-class education | Hands-on training | Collaborative community of peers and mentors. Locations.\n",
            "---\n",
            "Title: Is it possible to link courses to our linkdin profile? - DeepLearning.AI\n",
            "Link: https://community.deeplearning.ai/t/is-it-possible-to-link-courses-to-our-linkdin-profile/343537\n",
            "Snippet: Yes, you can share your certificate on LinkedIn. On Coursera website, click on your name then Accomplishments. Scroll down a little and you will see the list.\n",
            "---\n",
            "Title: Andrew Ng - DeepLearning.AI - LinkedIn\n",
            "Link: https://www.linkedin.com/in/andrewyng\n",
            "Snippet: Andrew Ng is an influencer. DeepLearning.AI University of California, Berkeley About Personal home page: http://andrewng.org\n",
            "---\n",
            "Title: What Organization to put in LinkedIn for the ML ... - DeepLearning.AI\n",
            "Link: https://community.deeplearning.ai/t/what-organization-to-put-in-linkedin-for-the-ml-and-dl-specializations/525223\n",
            "Snippet: DeepLearning.AI seems more useful, since putting “Stanford University” in your profile implies that you are enrolled there as a student. In ...\n",
            "---\n",
            "Title: DeepLearning.AI | LinkedIn\n",
            "Link: https://ky.linkedin.com/company/deeplearningai?trk=products_seo_search\n",
            "Snippet: Learn the skills to start or advance your AI career | World-class education | Hands-on training | Collaborative community of peers and mentors. Locations.\n",
            "---\n",
            "Title: DeepLearning.AI - LinkedIn\n",
            "Link: https://www.linkedin.com/products/deeplearningai/\n",
            "Snippet: DeepLearning.AI | Learn the skills to start or advance your AI career | World-class education | Hands-on training | Collaborative community of peers and mentors\n",
            "---\n",
            "Title: Andrew Ng - How DeepLearning.AI created quality courses - LinkedIn\n",
            "Link: https://www.linkedin.com/posts/andrewyng_openai-blocks-china-tests-for-human-level-activity-7216104446760476672-8MOb\n",
            "Snippet: Andrew your work in educating people on Machine Learning has been amazing. Your dedication and perseverance reflects in your courses. With time ...\n",
            "---\n",
            "Title: Deep Learning Specialization - Coursera\n",
            "Link: https://www.coursera.org/specializations/deep-learning\n",
            "Snippet: Become a Machine Learning expert. Master the fundamentals of deep learning and break into AI. Recently updated with cutting-edge techniques!\n",
            "---\n",
            "Title: John Santerre PhD - DeepLearning.AI | LinkedIn\n",
            "Link: https://www.linkedin.com/in/john-santerre-phd-91609b6\n",
            "Snippet: John Santerre PhD, DeepLearning.AI, The University of Chicago, About, Professor with a demonstrated more than 10 year history of working in the research.\n",
            "---\n",
            "\n",
            "\u001b[00m\n",
            "\u001b[32;1m\u001b[1;3mTo gather detailed information about DeepLearningAI, I've identified several useful sources. I will begin by visiting the LinkedIn profile of DeepLearningAI to find information about key personnel and recent activities.\n",
            "\n",
            "Action: Search the internet\n",
            "Action Input: {\"search_query\": \"DeepLearningAI company milestones and recent projects\"}\u001b[0m\u001b[95m \n",
            "\n",
            "\n",
            "Search results: Title: The Batch | DeepLearning.AI | AI News & Insights\n",
            "Link: https://www.deeplearning.ai/the-batch/\n",
            "Snippet: AI Agents Generate Novel Research, Google Imagen 3 Raises the Bar, Alibaba's Open Models for Specialized Tasks, Scaling Laws for Data Quality ... The Batch AI ...\n",
            "---\n",
            "Title: Generative AI Timeline: 9 Decades of Notable Milestones\n",
            "Link: https://www.cmswire.com/digital-experience/generative-ai-timeline-9-decades-of-notable-milestones/\n",
            "Snippet: 2022: Startup company Stability AI develops Stable Diffusion, a deep learning text-to-image model that generates images based on text ...\n",
            "---\n",
            "Title: sourcecode369/deeplearning.ai-projects - GitHub\n",
            "Link: https://github.com/sourcecode369/deeplearning.ai-projects\n",
            "Snippet: This repository contains Jupyter Notebook Files of all the projects that I completed during my summer internship online program in deeplearning.ai (Coursera).\n",
            "---\n",
            "Title: Deep Learning Specialization - DeepLearning.AI\n",
            "Link: https://www.deeplearning.ai/courses/deep-learning-specialization/\n",
            "Snippet: The Deep Learning Specialization is a foundational program that will help you understand the capabilities, challenges, and consequences of deep learning and ...\n",
            "---\n",
            "Title: Andrew Ng's Next Trick: Training a Million AI Experts\n",
            "Link: https://www.technologyreview.com/2017/08/08/150069/andrew-ngs-next-trick-training-a-million-ai-experts/\n",
            "Snippet: He says the deep-learning course is the first of three projects he plans to launch through his new startup, Deeplearning.ai.\n",
            "---\n",
            "Title: How long did you take to complete DeepLearning.ai? - Reddit\n",
            "Link: https://www.reddit.com/r/learnmachinelearning/comments/8fta6f/how_long_did_you_take_to_complete_deeplearningai/\n",
            "Snippet: I finished it in about 3 weeks, maybe 3-4 hours a day average. A lot of time is taken up by the videos of course. The assignments take 1-2 hours I'd say.\n",
            "---\n",
            "Title: Timeline of machine learning - Wikipedia\n",
            "Link: https://en.wikipedia.org/wiki/Timeline_of_machine_learning\n",
            "Snippet: This page is a timeline of machine learning. Major discoveries, achievements, milestones and other major events in machine learning are included.\n",
            "---\n",
            "Title: Andrew Ng: Opportunities in AI - 2023 - YouTube\n",
            "Link: https://www.youtube.com/watch?v=5p248yoa3oE\n",
            "Snippet: ... Business. This talk covers: Trends in AI Technologies and Tools ... Deep Learning ...\n",
            "---\n",
            "Title: The History of Artificial Intelligence, Machine Learning and Deep ...\n",
            "Link: https://www.algotive.ai/blog/the-history-of-artificial-intelligence-machine-learning-and-deep-learning\n",
            "Snippet: This article will briefly cover the most outstanding events of the prehistory, history, and revolution of Artificial Intelligence\n",
            "---\n",
            "Title: History and Evolution of Machine Learning: A Timeline - TechTarget\n",
            "Link: https://www.techtarget.com/whatis/A-Timeline-of-Machine-Learning-History\n",
            "Snippet: The history and evolution of machine learning dates from the early esoteric beginnings of neural networks to recent breakthroughs in ...\n",
            "---\n",
            "\n",
            "\u001b[00m\n",
            "\u001b[32;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mThought: I now can give a great answer\n",
            "Final Answer: \n",
            "\n",
            "**Comprehensive Report on DeepLearningAI**\n",
            "\n",
            "**Company Background:**\n",
            "DeepLearningAI is an education technology company founded by Andrew Ng, a global leader in artificial intelligence. The company is headquartered in Palo Alto, California, and is dedicated to making world-class AI education accessible globally. It provides online courses and specializations in AI and machine learning, empowering individuals and the global workforce to build an AI-powered future.\n",
            "\n",
            "**Key Personnel:**\n",
            "- **Andrew Ng**: Founder and CEO. He is a prominent figure in AI and has been involved in multiple AI-related initiatives and companies.\n",
            "- **Jonathan Heyne**: Chief Operating Officer. He plays a significant role in the operations and strategic direction of the company.\n",
            "\n",
            "**Recent Milestones:**\n",
            "- DeepLearningAI has been actively involved in educational initiatives, such as offering a free short course on automating LLM evaluations in collaboration with CircleCI.\n",
            "- The company continues to expand its course offerings and reach, with a focus on practical, hands-on training and creating a collaborative community for learners.\n",
            "\n",
            "**Identified Needs and Potential Areas for Value:**\n",
            "1. **Expanded Course Offerings**: As DeepLearningAI looks to broaden its educational content, CrewAI's solutions could support the creation of new AI-driven educational tools and platforms that enhance learning experiences.\n",
            "2. **Scalability of Operations**: Given the growing demand for AI education, CrewAI can offer scalable solutions that enable DeepLearningAI to efficiently manage and deliver its courses to a larger audience.\n",
            "3. **Community Engagement**: DeepLearningAI aims to foster a community of learners and mentors. CrewAI can provide tools that facilitate better interaction and engagement within this community.\n",
            "\n",
            "**Personalized Engagement Strategies:**\n",
            "- **Tailored Solutions Presentation**: Present CrewAI's solutions that specifically address the scalability and engagement needs of DeepLearningAI's platform.\n",
            "- **Collaborative Workshops**: Organize workshops to demonstrate how CrewAI's technology can be integrated into DeepLearningAI's current offerings to enhance user experience.\n",
            "- **Partnership for Co-Branded Courses**: Propose a partnership to develop co-branded courses that leverage CrewAI's AI expertise and DeepLearningAI's educational reach.\n",
            "\n",
            "This report provides a detailed overview of DeepLearningAI, highlighting potential areas where CrewAI can offer significant value. By aligning our solutions with their needs, we can forge a strong partnership and drive growth for both companies.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[1m\u001b[92m [DEBUG]: == [Sales Representative] Task output: **Comprehensive Report on DeepLearningAI**\n",
            "\n",
            "**Company Background:**\n",
            "DeepLearningAI is an education technology company founded by Andrew Ng, a global leader in artificial intelligence. The company is headquartered in Palo Alto, California, and is dedicated to making world-class AI education accessible globally. It provides online courses and specializations in AI and machine learning, empowering individuals and the global workforce to build an AI-powered future.\n",
            "\n",
            "**Key Personnel:**\n",
            "- **Andrew Ng**: Founder and CEO. He is a prominent figure in AI and has been involved in multiple AI-related initiatives and companies.\n",
            "- **Jonathan Heyne**: Chief Operating Officer. He plays a significant role in the operations and strategic direction of the company.\n",
            "\n",
            "**Recent Milestones:**\n",
            "- DeepLearningAI has been actively involved in educational initiatives, such as offering a free short course on automating LLM evaluations in collaboration with CircleCI.\n",
            "- The company continues to expand its course offerings and reach, with a focus on practical, hands-on training and creating a collaborative community for learners.\n",
            "\n",
            "**Identified Needs and Potential Areas for Value:**\n",
            "1. **Expanded Course Offerings**: As DeepLearningAI looks to broaden its educational content, CrewAI's solutions could support the creation of new AI-driven educational tools and platforms that enhance learning experiences.\n",
            "2. **Scalability of Operations**: Given the growing demand for AI education, CrewAI can offer scalable solutions that enable DeepLearningAI to efficiently manage and deliver its courses to a larger audience.\n",
            "3. **Community Engagement**: DeepLearningAI aims to foster a community of learners and mentors. CrewAI can provide tools that facilitate better interaction and engagement within this community.\n",
            "\n",
            "**Personalized Engagement Strategies:**\n",
            "- **Tailored Solutions Presentation**: Present CrewAI's solutions that specifically address the scalability and engagement needs of DeepLearningAI's platform.\n",
            "- **Collaborative Workshops**: Organize workshops to demonstrate how CrewAI's technology can be integrated into DeepLearningAI's current offerings to enhance user experience.\n",
            "- **Partnership for Co-Branded Courses**: Propose a partnership to develop co-branded courses that leverage CrewAI's AI expertise and DeepLearningAI's educational reach.\n",
            "\n",
            "This report provides a detailed overview of DeepLearningAI, highlighting potential areas where CrewAI can offer significant value. By aligning our solutions with their needs, we can forge a strong partnership and drive growth for both companies.\n",
            "\n",
            "\u001b[00m\n",
            "\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Lead Sales Representative\u001b[00m\n",
            "\u001b[1m\u001b[95m [INFO]: == Starting Task: Using the insights gathered from the lead profiling report on DeepLearningAI, craft a personalized outreach campaign aimed at Andrew Ng, the CEO of DeepLearningAI. The campaign should address their recent product launch and how our solutions can support their goals. Your communication must resonate with DeepLearningAI's company culture and values, demonstrating a deep understanding of their business and needs.\n",
            "Don't make assumptions and only use information you absolutely sure about.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mTo craft a personalized outreach campaign for Andrew Ng, I need to gather specific information about DeepLearningAI's recent product launch and align our solutions accordingly. I will first search the internet for recent news or information on DeepLearningAI’s recent product launch. \n",
            "\n",
            "Action: Search the internet\n",
            "Action Input: {\"search_query\": \"DeepLearningAI recent product launch 2023\"}\n",
            "\u001b[0m\u001b[95m \n",
            "\n",
            "\n",
            "Search results: Title: Top Stories of 2023: Generative Everything, Doomsday Visions ...\n",
            "Link: https://www.deeplearning.ai/the-batch/issue-228/\n",
            "Snippet: In 2023, the wave of generative AI washed over everything. And its expanding capabilities raised fears that intelligent machines might render humanity obsolete.\n",
            "---\n",
            "Title: Nov 29, 2023 | The Batch | AI News & Insights - DeepLearning.AI\n",
            "Link: https://www.deeplearning.ai/the-batch/tag/nov-29-2023/\n",
            "Snippet: Industrial Strength Language Model: Siemens and Microsoft launch GPT-powered Copilot for manufacturing machinery. ... ChatGPT is pitching in on the assembly line.\n",
            "---\n",
            "Title: DeepLearning.AI: Start or Advance Your Career in AI\n",
            "Link: https://www.deeplearning.ai/\n",
            "Snippet: Join over 7 million people learning how to use and build AI. AI Courses and Specializations. Build a foundation of machine learning and AI skills.\n",
            "---\n",
            "Title: Hopes for 2023 from Yoshua Bengio, Been Kim, Douwe Kiela, Reza ...\n",
            "Link: https://www.deeplearning.ai/the-batch/issue-177/\n",
            "Snippet: As we enter the new year, there is a growing hope that the recent explosion of generative AI will bring significant progress in active learning.\n",
            "---\n",
            "Title: The Batch | DeepLearning.AI | AI News & Insights\n",
            "Link: https://www.deeplearning.ai/the-batch/\n",
            "Snippet: The Batch AI News and Insights: After a recent price reduction by OpenAI, GPT-4o tokens now cost $4 per million tokens (using a blended rate that assumes 80% ...\n",
            "---\n",
            "Title: Product Development | The Batch - DeepLearning.AI\n",
            "Link: https://www.deeplearning.ai/the-batch/tag/product-development/\n",
            "Snippet: AWS Joins the Generative AI Race: AWS launches Bedrock, a generative AI platform. Amazon joined big-tech peers Google, Meta, and Microsoft in rolling out ...\n",
            "---\n",
            "Title: DeepLearning.AI and Coursera launch Generative AI for Everyone ...\n",
            "Link: https://blog.coursera.org/deeplearning-ai-and-coursera-launch-generative-ai-for-everyone-from-ai-pioneer-andrew-ng/\n",
            "Snippet: This beginner-level course will help everyone, including those with a nontechnical background, gain a deeper understanding of how generative AI works.\n",
            "---\n",
            "Title: Andrew Ng: Opportunities in AI - 2023 - YouTube\n",
            "Link: https://www.youtube.com/watch?v=5p248yoa3oE\n",
            "Snippet: This discussion took place on July 26, 2023, at Cemex Auditorium, Stanford University, and was ...\n",
            "---\n",
            "Title: 2023 Pie & AI Ambassador Spotlight: Armielyn Obinguar\n",
            "Link: https://www.deeplearning.ai/blog/2023-pie-ai-ambassador-spotlight-armielyn-obinguar-manila-philippines/\n",
            "Snippet: Armielyn Obinguar aims to grow the DeepLearning.AI community in the Philippines and keep positively impacting society.\n",
            "---\n",
            "Title: 11 New Technologies in AI: All Trends of 2023-2024 - devabit\n",
            "Link: https://devabit.com/blog/top-11-new-technologies-in-ai-exploring-the-latest-trends/\n",
            "Snippet: From GPT-4 and GANS to XAI and NLP, discover the new technologies in AI and find out how they can be implemented in your business to make a profit.\n",
            "---\n",
            "\n",
            "\u001b[00m\n",
            "\u001b[32;1m\u001b[1;3mThought: I found relevant information about DeepLearningAI's recent product launch. They have launched a course titled \"Generative AI for Everyone\" on Coursera, which aims to make generative AI accessible to individuals with nontechnical backgrounds. I will now use this information to craft a personalized outreach campaign for Andrew Ng, ensuring the communication aligns with DeepLearningAI's values and needs.\n",
            "\n",
            "Action: Sentiment Analysis Tool\n",
            "Action Input: {\"text\": \"Dear Andrew,\\n\\nI hope this message finds you well. I recently came across the exciting news about DeepLearningAI's launch of the 'Generative AI for Everyone' course on Coursera. This initiative beautifully aligns with your mission to make AI education accessible to all, and I commend you for this remarkable step forward.\\n\\nAt CrewAI, we share your passion for democratizing AI knowledge and are eager to explore how our solutions can further empower DeepLearningAI's goals. Our AI-driven educational tools are designed to enhance learning experiences, making them more engaging and scalable, which could be a perfect complement to your new course offerings.\\n\\nWe understand the importance of community engagement in education, and our tools facilitate active interaction, fostering a vibrant learning community. We believe that by integrating our solutions, DeepLearningAI can enhance its platform's scalability and reach, allowing even more learners to benefit from your outstanding courses.\\n\\nI would love the opportunity to discuss how we can collaborate to bring even more value to your learners. Are you available for a quick call next week to explore this further?\\n\\nLooking forward to the possibility of working together.\\n\\nWarm regards,\\n\\n[Your Name]\\nLead Sales Representative\\nCrewAI\"}\n",
            "\u001b[0m\u001b[95m \n",
            "\n",
            "positive\n",
            "\u001b[00m\n",
            "\u001b[32;1m\u001b[1;3mFinal Answer:\n",
            "\n",
            "**Email Draft 1:**\n",
            "\n",
            "Subject: Collaborating to Enhance \"Generative AI for Everyone\"\n",
            "\n",
            "Dear Andrew,\n",
            "\n",
            "I hope this message finds you well. I recently came across the exciting news about DeepLearningAI's launch of the \"Generative AI for Everyone\" course on Coursera. This initiative beautifully aligns with your mission to make AI education accessible to all, and I commend you for this remarkable step forward.\n",
            "\n",
            "At CrewAI, we share your passion for democratizing AI knowledge and are eager to explore how our solutions can further empower DeepLearningAI's goals. Our AI-driven educational tools are designed to enhance learning experiences, making them more engaging and scalable, which could be a perfect complement to your new course offerings.\n",
            "\n",
            "We understand the importance of community engagement in education, and our tools facilitate active interaction, fostering a vibrant learning community. We believe that by integrating our solutions, DeepLearningAI can enhance its platform's scalability and reach, allowing even more learners to benefit from your outstanding courses.\n",
            "\n",
            "I would love the opportunity to discuss how we can collaborate to bring even more value to your learners. Are you available for a quick call next week to explore this further?\n",
            "\n",
            "Looking forward to the possibility of working together.\n",
            "\n",
            "Warm regards,\n",
            "\n",
            "[Your Name]  \n",
            "Lead Sales Representative  \n",
            "CrewAI\n",
            "\n",
            "**Email Draft 2:**\n",
            "\n",
            "Subject: Elevating AI Education Together\n",
            "\n",
            "Dear Andrew,\n",
            "\n",
            "Congratulations on the successful launch of the \"Generative AI for Everyone\" course! This is a testament to DeepLearningAI's commitment to breaking barriers in AI education and empowering a diverse range of learners.\n",
            "\n",
            "At CrewAI, we are inspired by your vision and believe we can support this mission by providing innovative AI solutions that enhance educational delivery and engagement. Our technology focuses on creating adaptive learning environments that can seamlessly integrate with your current platforms, providing a scalable solution to meet growing demands.\n",
            "\n",
            "Additionally, our tools are designed to enhance community engagement, something we know is crucial to DeepLearningAI’s objectives. By fostering interactive and collaborative learning experiences, we can help build a thriving community around your educational initiatives.\n",
            "\n",
            "I’m keen to discuss how our solutions can add value to your new and existing projects. Could we schedule a meeting to explore potential collaboration opportunities?\n",
            "\n",
            "Thank you for considering this partnership. I look forward to your positive response.\n",
            "\n",
            "Best regards,\n",
            "\n",
            "[Your Name]  \n",
            "Lead Sales Representative  \n",
            "CrewAI\n",
            "\n",
            "**Email Draft 3:**\n",
            "\n",
            "Subject: Partnering for Greater Impact in AI Education\n",
            "\n",
            "Hi Andrew,\n",
            "\n",
            "I hope you’re doing well! I’m thrilled to hear about the \"Generative AI for Everyone\" course you’ve launched on Coursera. This effort is truly commendable and aligns perfectly with the global need for more inclusive AI education.\n",
            "\n",
            "CrewAI is at the forefront of developing tools that expand the reach and effectiveness of educational content. Our solutions are uniquely designed to enhance learning experiences by making them more interactive and scalable, which can be particularly beneficial as you continue to expand your course offerings.\n",
            "\n",
            "Furthermore, we understand the critical role of community in learning. Our platform can enhance community interaction and engagement, helping to build a supportive network of learners and mentors within DeepLearningAI.\n",
            "\n",
            "Would you be open to a brief discussion next week to explore how we can collaborate to enhance your educational impact even further? I am confident that together we can achieve remarkable outcomes.\n",
            "\n",
            "Thank you for your time, and I hope to hear from you soon.\n",
            "\n",
            "Sincerely,\n",
            "\n",
            "[Your Name]  \n",
            "Lead Sales Representative  \n",
            "CrewAI\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[1m\u001b[92m [DEBUG]: == [Lead Sales Representative] Task output: **Email Draft 1:**\n",
            "\n",
            "Subject: Collaborating to Enhance \"Generative AI for Everyone\"\n",
            "\n",
            "Dear Andrew,\n",
            "\n",
            "I hope this message finds you well. I recently came across the exciting news about DeepLearningAI's launch of the \"Generative AI for Everyone\" course on Coursera. This initiative beautifully aligns with your mission to make AI education accessible to all, and I commend you for this remarkable step forward.\n",
            "\n",
            "At CrewAI, we share your passion for democratizing AI knowledge and are eager to explore how our solutions can further empower DeepLearningAI's goals. Our AI-driven educational tools are designed to enhance learning experiences, making them more engaging and scalable, which could be a perfect complement to your new course offerings.\n",
            "\n",
            "We understand the importance of community engagement in education, and our tools facilitate active interaction, fostering a vibrant learning community. We believe that by integrating our solutions, DeepLearningAI can enhance its platform's scalability and reach, allowing even more learners to benefit from your outstanding courses.\n",
            "\n",
            "I would love the opportunity to discuss how we can collaborate to bring even more value to your learners. Are you available for a quick call next week to explore this further?\n",
            "\n",
            "Looking forward to the possibility of working together.\n",
            "\n",
            "Warm regards,\n",
            "\n",
            "[Your Name]  \n",
            "Lead Sales Representative  \n",
            "CrewAI\n",
            "\n",
            "**Email Draft 2:**\n",
            "\n",
            "Subject: Elevating AI Education Together\n",
            "\n",
            "Dear Andrew,\n",
            "\n",
            "Congratulations on the successful launch of the \"Generative AI for Everyone\" course! This is a testament to DeepLearningAI's commitment to breaking barriers in AI education and empowering a diverse range of learners.\n",
            "\n",
            "At CrewAI, we are inspired by your vision and believe we can support this mission by providing innovative AI solutions that enhance educational delivery and engagement. Our technology focuses on creating adaptive learning environments that can seamlessly integrate with your current platforms, providing a scalable solution to meet growing demands.\n",
            "\n",
            "Additionally, our tools are designed to enhance community engagement, something we know is crucial to DeepLearningAI’s objectives. By fostering interactive and collaborative learning experiences, we can help build a thriving community around your educational initiatives.\n",
            "\n",
            "I’m keen to discuss how our solutions can add value to your new and existing projects. Could we schedule a meeting to explore potential collaboration opportunities?\n",
            "\n",
            "Thank you for considering this partnership. I look forward to your positive response.\n",
            "\n",
            "Best regards,\n",
            "\n",
            "[Your Name]  \n",
            "Lead Sales Representative  \n",
            "CrewAI\n",
            "\n",
            "**Email Draft 3:**\n",
            "\n",
            "Subject: Partnering for Greater Impact in AI Education\n",
            "\n",
            "Hi Andrew,\n",
            "\n",
            "I hope you’re doing well! I’m thrilled to hear about the \"Generative AI for Everyone\" course you’ve launched on Coursera. This effort is truly commendable and aligns perfectly with the global need for more inclusive AI education.\n",
            "\n",
            "CrewAI is at the forefront of developing tools that expand the reach and effectiveness of educational content. Our solutions are uniquely designed to enhance learning experiences by making them more interactive and scalable, which can be particularly beneficial as you continue to expand your course offerings.\n",
            "\n",
            "Furthermore, we understand the critical role of community in learning. Our platform can enhance community interaction and engagement, helping to build a supportive network of learners and mentors within DeepLearningAI.\n",
            "\n",
            "Would you be open to a brief discussion next week to explore how we can collaborate to enhance your educational impact even further? I am confident that together we can achieve remarkable outcomes.\n",
            "\n",
            "Thank you for your time, and I hope to hear from you soon.\n",
            "\n",
            "Sincerely,\n",
            "\n",
            "[Your Name]  \n",
            "Lead Sales Representative  \n",
            "CrewAI\n",
            "\n",
            "\u001b[00m\n"
          ]
        }
      ],
      "source": [
        "inputs = {\n",
        "    \"lead_name\": \"DeepLearningAI\",\n",
        "    \"industry\": \"Online Learning Platform\",\n",
        "    \"key_decision_maker\": \"Andrew Ng\",\n",
        "    \"position\": \"CEO\",\n",
        "    \"milestone\": \"product launch\"\n",
        "}\n",
        "\n",
        "result = crew.kickoff(inputs=inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lz-0p6jrDx9S"
      },
      "source": [
        "- Display the final result as Markdown."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 46,
        "id": "MaHHs9ySDx9S",
        "outputId": "972a3ddd-c3c9-492f-d046-479991e6bedc"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "**Email Draft 1:**\n",
              "\n",
              "Subject: Collaborating to Enhance \"Generative AI for Everyone\"\n",
              "\n",
              "Dear Andrew,\n",
              "\n",
              "I hope this message finds you well. I recently came across the exciting news about DeepLearningAI's launch of the \"Generative AI for Everyone\" course on Coursera. This initiative beautifully aligns with your mission to make AI education accessible to all, and I commend you for this remarkable step forward.\n",
              "\n",
              "At CrewAI, we share your passion for democratizing AI knowledge and are eager to explore how our solutions can further empower DeepLearningAI's goals. Our AI-driven educational tools are designed to enhance learning experiences, making them more engaging and scalable, which could be a perfect complement to your new course offerings.\n",
              "\n",
              "We understand the importance of community engagement in education, and our tools facilitate active interaction, fostering a vibrant learning community. We believe that by integrating our solutions, DeepLearningAI can enhance its platform's scalability and reach, allowing even more learners to benefit from your outstanding courses.\n",
              "\n",
              "I would love the opportunity to discuss how we can collaborate to bring even more value to your learners. Are you available for a quick call next week to explore this further?\n",
              "\n",
              "Looking forward to the possibility of working together.\n",
              "\n",
              "Warm regards,\n",
              "\n",
              "[Your Name]  \n",
              "Lead Sales Representative  \n",
              "CrewAI\n",
              "\n",
              "**Email Draft 2:**\n",
              "\n",
              "Subject: Elevating AI Education Together\n",
              "\n",
              "Dear Andrew,\n",
              "\n",
              "Congratulations on the successful launch of the \"Generative AI for Everyone\" course! This is a testament to DeepLearningAI's commitment to breaking barriers in AI education and empowering a diverse range of learners.\n",
              "\n",
              "At CrewAI, we are inspired by your vision and believe we can support this mission by providing innovative AI solutions that enhance educational delivery and engagement. Our technology focuses on creating adaptive learning environments that can seamlessly integrate with your current platforms, providing a scalable solution to meet growing demands.\n",
              "\n",
              "Additionally, our tools are designed to enhance community engagement, something we know is crucial to DeepLearningAI’s objectives. By fostering interactive and collaborative learning experiences, we can help build a thriving community around your educational initiatives.\n",
              "\n",
              "I’m keen to discuss how our solutions can add value to your new and existing projects. Could we schedule a meeting to explore potential collaboration opportunities?\n",
              "\n",
              "Thank you for considering this partnership. I look forward to your positive response.\n",
              "\n",
              "Best regards,\n",
              "\n",
              "[Your Name]  \n",
              "Lead Sales Representative  \n",
              "CrewAI\n",
              "\n",
              "**Email Draft 3:**\n",
              "\n",
              "Subject: Partnering for Greater Impact in AI Education\n",
              "\n",
              "Hi Andrew,\n",
              "\n",
              "I hope you’re doing well! I’m thrilled to hear about the \"Generative AI for Everyone\" course you’ve launched on Coursera. This effort is truly commendable and aligns perfectly with the global need for more inclusive AI education.\n",
              "\n",
              "CrewAI is at the forefront of developing tools that expand the reach and effectiveness of educational content. Our solutions are uniquely designed to enhance learning experiences by making them more interactive and scalable, which can be particularly beneficial as you continue to expand your course offerings.\n",
              "\n",
              "Furthermore, we understand the critical role of community in learning. Our platform can enhance community interaction and engagement, helping to build a supportive network of learners and mentors within DeepLearningAI.\n",
              "\n",
              "Would you be open to a brief discussion next week to explore how we can collaborate to enhance your educational impact even further? I am confident that together we can achieve remarkable outcomes.\n",
              "\n",
              "Thank you for your time, and I hope to hear from you soon.\n",
              "\n",
              "Sincerely,\n",
              "\n",
              "[Your Name]  \n",
              "Lead Sales Representative  \n",
              "CrewAI"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from IPython.display import Markdown\n",
        "Markdown(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 29,
        "id": "Bc7NMndmDx9S"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 29,
        "id": "xPhgnje7Dx9S"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OE9pEjWoeLm4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}